{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f56d157a-603d-4339-a5c9-76e2129f35f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import rasterio\n",
    "from rasterio import features\n",
    "import rasterio.warp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.ndimage import zoom\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c064651a-5d04-42e8-82c8-6730aa9533eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base values\n",
    "channel_descriptions = ['M11', 'I2', 'I1', 'NDVI_last', 'EVI2_last', 'total precipitation', 'wind speed', 'wind direction', 'minimum temperature', 'maximum temperature', 'energy release component', 'specific humidity', 'slope', 'aspect', 'elevation', 'pdsi', 'LC_Type1', 'total_precipitation_surface_last', 'forecast wind speed', 'forecast wind direction', 'forecast temperature', 'forecast specific humidity', 'active fire']\n",
    "\n",
    "min_values = [np.float32(-100.0),\n",
    "  np.float32(-100.0),\n",
    "  np.float32(-100.0),\n",
    "  np.float32(-9863.268),\n",
    "  np.float32(-4422.217),\n",
    "  np.float32(0.0),\n",
    "  np.float32(0.0),\n",
    "  np.float32(0.0),\n",
    "  np.float32(0.0),\n",
    "  np.float32(0.0),\n",
    "  np.float32(0.0),\n",
    "  np.float32(0.0),\n",
    "  np.float32(0.0),\n",
    "  np.float32(0.0),\n",
    "  np.float32(-84.0),\n",
    "  np.float32(-6.72),\n",
    "  np.float32(1.0),\n",
    "  np.float32(0.0),\n",
    "  np.float32(0.0),\n",
    "  np.float32(-89.999214),\n",
    "  np.float32(-13.984883),\n",
    "  np.float32(0.0),\n",
    "  np.float32(0.0)]\n",
    "\n",
    "max_values = [np.float32(15976.0),\n",
    "  np.float32(15799.0),\n",
    "  np.float32(15744.0),\n",
    "  np.float32(9975.073),\n",
    "  np.float32(9856.787),\n",
    "  np.float32(122.0),\n",
    "  np.float32(16.2),\n",
    "  np.float32(360.0),\n",
    "  np.float32(311.8),\n",
    "  np.float32(325.4),\n",
    "  np.float32(122.0),\n",
    "  np.float32(0.01888),\n",
    "  np.float32(63.85685),\n",
    "  np.float32(359.42383),\n",
    "  np.float32(4268.336),\n",
    "  np.float32(8.28),\n",
    "  np.float32(17.0),\n",
    "  np.float32(204.1875),\n",
    "  np.float32(14.295916),\n",
    "  np.float32(89.98897),\n",
    "  np.float32(39.505894),\n",
    "  np.float32(0.0122514665),\n",
    "  np.float32(2218.0)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53d5d05a-27c2-46f9-8163-2aa741b11ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading...\n",
      "Progress: 1/7 (1)\n",
      "Progress: 2/7 (2)\n",
      "Progress: 3/7 (3)\n",
      "Progress: 4/7 (4)\n",
      "Progress: 5/7 (5)\n",
      "Progress: 6/7 (6)\n",
      "Progress: 7/7 (7)\n",
      "Loading done! Count = 168 | Shape = (23, 128, 128)\n",
      "(168, 23, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "fire_folders = []\n",
    "look_back = 5   # 5 days sequence\n",
    "all_frames = []\n",
    "data_limit, loop_counter, loop_start = 7, 0, 0\n",
    "channel_descriptions = None\n",
    "base_path = \"./data\"\n",
    "\n",
    "target_shape_h, target_shape_w = 128, 128\n",
    "\n",
    "print('Loading...')\n",
    "\n",
    "for fire_folder in os.listdir(base_path):\n",
    "    loop_counter += 1\n",
    "    if loop_counter - loop_start > data_limit:\n",
    "        break\n",
    "    if loop_counter < loop_start:\n",
    "        continue\n",
    "    print('Progress: {0}/{1} ({2})'.format(loop_counter - loop_start, data_limit, loop_counter))\n",
    "    fire_folders.append(fire_folder)\n",
    "    for image_name in os.listdir(base_path + f\"/{fire_folder}\"):\n",
    "        file_path = base_path + f\"/{fire_folder}/{image_name}\"\n",
    "        \n",
    "        with rasterio.open(file_path, 'r') as geotiff:\n",
    "            src = geotiff.read()\n",
    "            channel_descriptions = geotiff.descriptions\n",
    "            zoom_factor = (1, target_shape_h / src.shape[1], target_shape_w / src.shape[2])\n",
    "            resized_src = zoom(src, zoom_factor, order=1)\n",
    "            resized_src = np.nan_to_num(resized_src, copy=True)\n",
    "            all_frames.append(resized_src)\n",
    "\n",
    "print(f'Loading done! Count = {len(all_frames)} | Shape = {all_frames[0].shape}')\n",
    "\n",
    "data_frames = np.stack(all_frames)\n",
    "print(data_frames.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f59353c-ca4d-4455-9326-6478b164fe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, minmax_scale\n",
    "\n",
    "#data_frames = (data_frames - min_bound) / (max_bound - min_bound)\n",
    "\n",
    "for c in range(23):\n",
    "    data_frames[:, c, :, :] = (data_frames[:, c, :, :] - min_values[c]) / (max_values[c] - min_values[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb4b0d0c-e5f9-4ab5-a663-879f4767dd50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float32(0.0), np.float32(1.0))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(data_frames), np.max(data_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e674442d-a46c-4283-886b-496b80cc1fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(163, 5, 23, 128, 128)\n",
      "(163, 1, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "Y = []\n",
    "\n",
    "for t in range(0, data_frames.shape[0] - look_back):\n",
    "    x_seq = data_frames[t:t+look_back]               # shape: (5, 23, H, W)\n",
    "    y_mask = data_frames[t + look_back, 22]           # fire mask from channel 22\n",
    "\n",
    "    X.append(x_seq)\n",
    "    Y.append(y_mask)     # binarize\n",
    "\n",
    "X = np.stack(X)  # shape: (273, 5, 23, 128, 128)\n",
    "Y = np.expand_dims(np.stack(Y), axis=1)  # shape: (273, 1, 128, 128)\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d756f23-2fe5-4f59-b49b-49e306fab13a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((130, 5, 23, 128, 128),\n",
       " (130, 1, 128, 128),\n",
       " (33, 5, 23, 128, 128),\n",
       " (33, 1, 128, 128))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_index = int(X.shape[0] * 0.8)\n",
    "\n",
    "X_train = X[:split_index]\n",
    "X_val = X[split_index:]\n",
    "\n",
    "Y_train = Y[:split_index]\n",
    "Y_val = Y[split_index:]\n",
    "\n",
    "X_train.shape, Y_train.shape, X_val.shape, Y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6aeafcd9-88e5-4d20-80f8-5d108a0395a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([130, 5, 23, 128, 128]),\n",
       " torch.Size([130, 1, 128, 128]),\n",
       " torch.Size([33, 5, 23, 128, 128]),\n",
       " torch.Size([33, 1, 128, 128]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = torch.tensor(X_train).float()\n",
    "Y_train = torch.tensor(Y_train).float()\n",
    "\n",
    "X_val = torch.tensor(X_val).float()\n",
    "Y_val = torch.tensor(Y_val).float()\n",
    "\n",
    "X_train.shape, Y_train.shape, X_val.shape, Y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "095f8971-1e58-4f2b-90d6-73bb5a1f3d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130, 33)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class WildfireDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.Y[i]\n",
    "\n",
    "train_dataset = WildfireDataset(X_train, Y_train)\n",
    "val_dataset = WildfireDataset(X_val, Y_val)\n",
    "\n",
    "len(train_dataset), len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34f03481-a655-4046-b0ce-1e3eeea5c23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53148a0f-90b6-4275-adbb-adb9684ee08e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbc8b996-03b7-4428-a716-7008018fd375",
   "metadata": {},
   "outputs": [],
   "source": [
    "import convlstm\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        orig_size = (330, 257)\n",
    "\n",
    "        self.clstm = convlstm.ConvLSTM(\n",
    "            input_size=(128, 128),\n",
    "            input_dim=23,\n",
    "            hidden_dim=[64],\n",
    "            kernel_size=(3, 3),\n",
    "            num_layers=1\n",
    "        )\n",
    "        # (8, 64, 128, 128)\n",
    "        \n",
    "        self.head = nn.Sequential(\n",
    "            nn.Conv2d(64, 1, kernel_size=3, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        # (8, 1, 128, 128)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        outputs, last_states = self.clstm(x)\n",
    "\n",
    "        x = outputs[0][:, -1, :, :, :]\n",
    "        x = self.head(x)\n",
    "        return x\n",
    "\n",
    "model = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9aa07e85-e851-4499-bab2-3bea6547806a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1.0):\n",
    "        super().__init__()\n",
    "        self.smooth = smooth\n",
    "        self.bce = nn.BCELoss()\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        bce_loss = self.bce(y_pred, y_true)\n",
    "        # (8, 1, 128, 128)\n",
    "\n",
    "        y_pred_flat = y_pred.view(y_pred.size(0), -1) # (8, 16384)\n",
    "        y_true_flat = y_true.view(y_true.size(0), -1) # (8, 16384)\n",
    "\n",
    "        intersection = (y_pred_flat * y_true_flat).sum(dim=1)\n",
    "        union = y_pred_flat.sum(dim=1) + y_true_flat.sum(dim=1)\n",
    "\n",
    "        dice_score = (2 * intersection + self.smooth) / (union + self.smooth)\n",
    "        dice_loss = 1 - dice_score.mean()\n",
    "        \n",
    "        return dice_loss\n",
    "\n",
    "class BCEWeightedLoss(nn.Module):\n",
    "    def __init__(self, eps=1e-7):\n",
    "        super(BCEWeightedLoss, self).__init__()\n",
    "        self.eps = eps  # to avoid log(0)\n",
    "        self.weight = 60.0\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        \"\"\"\n",
    "        y_pred: probabilities after sigmoid, shape (B, 1, H, W)\n",
    "        y_true: binary targets, shape (B, 1, H, W)\n",
    "        \"\"\"\n",
    "        # Clamp predictions to avoid log(0)\n",
    "        y_pred = torch.clamp(y_pred, self.eps, 1.0 - self.eps)\n",
    "\n",
    "        # BCE loss calculation\n",
    "        loss = - (y_true * self.weight * torch.log(y_pred) + (1 - y_true) * torch.log(1 - y_pred))\n",
    "\n",
    "        return loss.mean()  # return scalar loss\n",
    "\n",
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self, eps=1e-7):\n",
    "        super(CustomLoss, self).__init__()\n",
    "        self.eps = eps\n",
    "        self.strength = 0.5\n",
    "        self.weight = 50.0\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        \"\"\"\n",
    "        y_pred: probabilities after sigmoid, shape (B, 1, H, W)\n",
    "        y_true: binary targets, shape (B, 1, H, W)\n",
    "        \"\"\"\n",
    "        # Clamp predictions to avoid log(0)\n",
    "        y_pred = torch.clamp(y_pred, self.eps, 1.0 - self.eps)\n",
    "\n",
    "        loss = (y_pred - y_true) ** self.strength\n",
    "\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77b7b71d-004f-479f-8c09-651d960137f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\neelr\\AppData\\Local\\Temp\\ipykernel_11916\\1023116336.py:20: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
      "Consider using tensor.detach() first. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\Scalar.cpp:23.)\n",
      "  running_loss += loss.item()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4, Loss: nan\n",
      "Batch 8, Loss: nan\n",
      "Batch 12, Loss: nan\n",
      "Batch 16, Loss: nan\n",
      "\n",
      "Val Loss: nan\n",
      "**********************************************************\n",
      "\n",
      "Epoch: 2\n",
      "Batch 4, Loss: nan\n",
      "Batch 8, Loss: nan\n",
      "Batch 12, Loss: nan\n",
      "Batch 16, Loss: nan\n",
      "\n",
      "Val Loss: nan\n",
      "**********************************************************\n",
      "\n",
      "Epoch: 3\n",
      "Batch 4, Loss: nan\n",
      "Batch 8, Loss: nan\n",
      "Batch 12, Loss: nan\n",
      "Batch 16, Loss: nan\n",
      "\n",
      "Val Loss: nan\n",
      "**********************************************************\n",
      "\n",
      "Epoch: 4\n",
      "Batch 4, Loss: nan\n",
      "Batch 8, Loss: nan\n",
      "Batch 12, Loss: nan\n",
      "Batch 16, Loss: nan\n",
      "\n",
      "Val Loss: nan\n",
      "**********************************************************\n",
      "\n",
      "Epoch: 5\n",
      "Batch 4, Loss: nan\n",
      "Batch 8, Loss: nan\n",
      "Batch 12, Loss: nan\n",
      "Batch 16, Loss: nan\n",
      "\n",
      "Val Loss: nan\n",
      "**********************************************************\n",
      "\n",
      "Epoch: 6\n",
      "Batch 4, Loss: nan\n",
      "Batch 8, Loss: nan\n",
      "Batch 12, Loss: nan\n",
      "Batch 16, Loss: nan\n",
      "\n",
      "Val Loss: nan\n",
      "**********************************************************\n",
      "\n",
      "Epoch: 7\n",
      "Batch 4, Loss: nan\n",
      "Batch 8, Loss: nan\n",
      "Batch 12, Loss: nan\n",
      "Batch 16, Loss: nan\n",
      "\n",
      "Val Loss: nan\n",
      "**********************************************************\n",
      "\n",
      "Epoch: 8\n",
      "Batch 4, Loss: nan\n",
      "Batch 8, Loss: nan\n",
      "Batch 12, Loss: nan\n",
      "Batch 16, Loss: nan\n",
      "\n",
      "Val Loss: nan\n",
      "**********************************************************\n",
      "\n",
      "Epoch: 9\n",
      "Batch 4, Loss: nan\n",
      "Batch 8, Loss: nan\n",
      "Batch 12, Loss: nan\n",
      "Batch 16, Loss: nan\n",
      "\n",
      "Val Loss: nan\n",
      "**********************************************************\n",
      "\n",
      "Epoch: 10\n",
      "Batch 4, Loss: nan\n",
      "Batch 8, Loss: nan\n",
      "Batch 12, Loss: nan\n",
      "Batch 16, Loss: nan\n",
      "\n",
      "Val Loss: nan\n",
      "**********************************************************\n",
      "\n",
      "Epoch: 11\n",
      "Batch 4, Loss: nan\n",
      "Batch 8, Loss: nan\n",
      "Batch 12, Loss: nan\n",
      "Batch 16, Loss: nan\n",
      "\n",
      "Val Loss: nan\n",
      "**********************************************************\n",
      "\n",
      "Epoch: 12\n",
      "Batch 4, Loss: nan\n",
      "Batch 8, Loss: nan\n",
      "Batch 12, Loss: nan\n",
      "Batch 16, Loss: nan\n",
      "\n",
      "Val Loss: nan\n",
      "**********************************************************\n",
      "\n",
      "Epoch: 13\n",
      "Batch 4, Loss: nan\n",
      "Batch 8, Loss: nan\n",
      "Batch 12, Loss: nan\n",
      "Batch 16, Loss: nan\n",
      "\n",
      "Val Loss: nan\n",
      "**********************************************************\n",
      "\n",
      "Epoch: 14\n",
      "Batch 4, Loss: nan\n",
      "Batch 8, Loss: nan\n",
      "Batch 12, Loss: nan\n",
      "Batch 16, Loss: nan\n",
      "\n",
      "Val Loss: nan\n",
      "**********************************************************\n",
      "\n",
      "Epoch: 15\n",
      "Batch 4, Loss: nan\n",
      "Batch 8, Loss: nan\n",
      "Batch 12, Loss: nan\n",
      "Batch 16, Loss: nan\n",
      "\n",
      "Val Loss: nan\n",
      "**********************************************************\n",
      "\n",
      "Epoch: 16\n",
      "Batch 4, Loss: nan\n",
      "Batch 8, Loss: nan\n",
      "Batch 12, Loss: nan\n",
      "Batch 16, Loss: nan\n",
      "\n",
      "Val Loss: nan\n",
      "**********************************************************\n",
      "\n",
      "Epoch: 17\n",
      "Batch 4, Loss: nan\n",
      "Batch 8, Loss: nan\n",
      "Batch 12, Loss: nan\n",
      "Batch 16, Loss: nan\n",
      "\n",
      "Val Loss: nan\n",
      "**********************************************************\n",
      "\n",
      "Epoch: 18\n",
      "Batch 4, Loss: nan\n",
      "Batch 8, Loss: nan\n",
      "Batch 12, Loss: nan\n",
      "Batch 16, Loss: nan\n",
      "\n",
      "Val Loss: nan\n",
      "**********************************************************\n",
      "\n",
      "Epoch: 19\n",
      "Batch 4, Loss: nan\n",
      "Batch 8, Loss: nan\n",
      "Batch 12, Loss: nan\n",
      "Batch 16, Loss: nan\n",
      "\n",
      "Val Loss: nan\n",
      "**********************************************************\n",
      "\n",
      "Epoch: 20\n",
      "Batch 4, Loss: nan\n",
      "Batch 8, Loss: nan\n",
      "Batch 12, Loss: nan\n",
      "Batch 16, Loss: nan\n",
      "\n",
      "Val Loss: nan\n",
      "**********************************************************\n",
      "\n",
      "Epoch: 21\n",
      "Batch 4, Loss: nan\n",
      "Batch 8, Loss: nan\n",
      "Batch 12, Loss: nan\n",
      "Batch 16, Loss: nan\n",
      "\n",
      "Val Loss: nan\n",
      "**********************************************************\n",
      "\n",
      "Epoch: 22\n",
      "Batch 4, Loss: nan\n",
      "Batch 8, Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lr = 0.001 # 0.0001\n",
    "num_epochs = 25\n",
    "\n",
    "loss_fn = BCEWeightedLoss()\n",
    "loss_fn = CustomLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "print_batch_every = 4\n",
    "\n",
    "def train(epoch):\n",
    "    model.train(True)\n",
    "    print(f\"Epoch: {epoch + 1}\")\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for batch_index, batch in enumerate(train_loader):\n",
    "        x_batch, y_batch = batch[0].to(device), batch[1].to(device)\n",
    "        y_pred = model(x_batch)\n",
    "\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_index % print_batch_every == (print_batch_every - 1):\n",
    "            avg_loss_across_batches = running_loss / print_batch_every\n",
    "            print('Batch {0}, Loss: {1:.3f}'.format(batch_index + 1, avg_loss_across_batches))\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    print()\n",
    "\n",
    "def validate():\n",
    "    model.train(False)\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch_index, batch in enumerate(val_loader):\n",
    "        x_batch, y_batch = batch[0].to(device), batch[1].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            y_pred = model(x_batch)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    avg_loss_across_batches = running_loss / len(val_loader)\n",
    "    print('Val Loss: {0:.3f}'.format(avg_loss_across_batches))\n",
    "    print('**********************************************************')\n",
    "    print()\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train(epoch)\n",
    "    validate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b020e92-034b-4cf9-afe8-b8e526a4fd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_index, batch in enumerate(train_loader):\n",
    "    if batch_index == 4:\n",
    "        x_batch, y_batch = batch[0].to(device), batch[1].to(device)\n",
    "        y_pred = model(x_batch)\n",
    "        print(\"found\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ee2e1d-f6f9-4f6d-a64b-024357061958",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.max(y_batch), torch.max(y_pred), torch.min(y_batch), torch.min(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db0f37b-e193-49eb-ace0-16593f3c1122",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_batch_np = y_batch.cpu().detach().numpy()\n",
    "y_pred_np = y_pred.cpu().detach().numpy()\n",
    "\n",
    "y_pred_avg = (np.min(y_pred_np) + np.max(y_pred_np)) / 2.0\n",
    "#y_pred_np = (y_pred_np - 0.0) / (0.65 - 0.0)\n",
    "\n",
    "y_batch_np.shape, y_pred_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e8257c-a5f6-445f-a4dc-79de037cc9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(y_pred_np), np.min(y_pred_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f80b709-4a10-4f92-83a9-08ba95ffa130",
   "metadata": {},
   "outputs": [],
   "source": [
    "splt_val = 0.15\n",
    "\n",
    "for i in range(y_batch_np.shape[0]):\n",
    "    plt.figure()\n",
    "    plt.title(f\"Actual {i + 1}\")\n",
    "    plt.imshow(y_batch_np[i, 0])\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title(f\"Predicted {i + 1}\")\n",
    "    val = y_pred_np[i, 0]\n",
    "    plt.imshow(np.piecewise(val, [val < splt_val, val >= splt_val], [0, 1]))\n",
    "    plt.imshow(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfef00d6-b688-4fa6-b29d-b0d18308fd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_index, batch in enumerate(val_loader):\n",
    "    if batch_index == 2:\n",
    "        x_batch, y_batch = batch[0].to(device), batch[1].to(device)\n",
    "        y_pred = model(x_batch)\n",
    "        print(\"found\")\n",
    "        break\n",
    "\n",
    "print(torch.max(y_batch), torch.max(y_pred), torch.min(y_batch), torch.min(y_pred))\n",
    "\n",
    "y_batch_np = y_batch.cpu().detach().numpy()\n",
    "y_pred_np = y_pred.cpu().detach().numpy()\n",
    "\n",
    "for i in range(y_batch_np.shape[0]):\n",
    "    plt.figure()\n",
    "    plt.title(f\"Actual {i + 1}\")\n",
    "    plt.imshow(y_batch_np[i, 0])\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title(f\"Predicted {i + 1}\")\n",
    "    #plt.imshow(np.piecewise(y_pred_np[i, 0], [y_pred_np[i, 0] < 0.08, y_pred_np[i, 0] >= 0.08], [0, 1]))\n",
    "    plt.imshow(y_pred_np[i, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7b984d-17ce-4bd2-9929-fd8d96e4ba1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
