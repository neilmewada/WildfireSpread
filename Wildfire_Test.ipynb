{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "626f0aa0-01b3-437f-a489-4785c8a2abf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import rasterio\n",
    "from rasterio import features\n",
    "import rasterio.warp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.ndimage import zoom\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36c13b0c-8d2f-4e19-962c-001de4d764a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base values\n",
    "channel_descriptions = ['M11', 'I2', 'I1', 'NDVI_last', 'EVI2_last', 'total precipitation', 'wind speed', 'wind direction', 'minimum temperature', 'maximum temperature', 'energy release component', 'specific humidity', 'slope', 'aspect', 'elevation', 'pdsi', 'LC_Type1', 'total_precipitation_surface_last', 'forecast wind speed', 'forecast wind direction', 'forecast temperature', 'forecast specific humidity', 'active fire']\n",
    "\n",
    "min_values = [np.float32(-100.0),\n",
    "  np.float32(-100.0),\n",
    "  np.float32(-100.0),\n",
    "  np.float32(-9863.268),\n",
    "  np.float32(-4422.217),\n",
    "  np.float32(0.0),\n",
    "  np.float32(0.0),\n",
    "  np.float32(0.0),\n",
    "  np.float32(0.0),\n",
    "  np.float32(0.0),\n",
    "  np.float32(0.0),\n",
    "  np.float32(0.0),\n",
    "  np.float32(0.0),\n",
    "  np.float32(0.0),\n",
    "  np.float32(-84.0),\n",
    "  np.float32(-6.72),\n",
    "  np.float32(1.0),\n",
    "  np.float32(0.0),\n",
    "  np.float32(0.0),\n",
    "  np.float32(-89.999214),\n",
    "  np.float32(-13.984883),\n",
    "  np.float32(0.0),\n",
    "  np.float32(0.0)]\n",
    "\n",
    "maX_testues = [np.float32(15976.0),\n",
    "  np.float32(15799.0),\n",
    "  np.float32(15744.0),\n",
    "  np.float32(9975.073),\n",
    "  np.float32(9856.787),\n",
    "  np.float32(122.0),\n",
    "  np.float32(16.2),\n",
    "  np.float32(360.0),\n",
    "  np.float32(311.8),\n",
    "  np.float32(325.4),\n",
    "  np.float32(122.0),\n",
    "  np.float32(0.01888),\n",
    "  np.float32(63.85685),\n",
    "  np.float32(359.42383),\n",
    "  np.float32(4268.336),\n",
    "  np.float32(8.28),\n",
    "  np.float32(17.0),\n",
    "  np.float32(204.1875),\n",
    "  np.float32(14.295916),\n",
    "  np.float32(89.98897),\n",
    "  np.float32(39.505894),\n",
    "  np.float32(0.0122514665),\n",
    "  np.float32(2218.0)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f6a66c5-9ab9-41c8-bef3-2cbb2ac8b049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading...\n",
      "Progress: 1/30 (1)\n",
      "Progress: 2/30 (2)\n",
      "Progress: 3/30 (3)\n",
      "Progress: 4/30 (4)\n",
      "Progress: 5/30 (5)\n",
      "Progress: 6/30 (6)\n",
      "Progress: 7/30 (7)\n",
      "Progress: 8/30 (8)\n",
      "Progress: 9/30 (9)\n",
      "Progress: 10/30 (10)\n",
      "Progress: 11/30 (11)\n",
      "Progress: 12/30 (12)\n",
      "Progress: 13/30 (13)\n",
      "Progress: 14/30 (14)\n",
      "Progress: 15/30 (15)\n",
      "Progress: 16/30 (16)\n",
      "Progress: 17/30 (17)\n",
      "Progress: 18/30 (18)\n",
      "Progress: 19/30 (19)\n",
      "Progress: 20/30 (20)\n",
      "Progress: 21/30 (21)\n",
      "Progress: 22/30 (22)\n",
      "Progress: 23/30 (23)\n",
      "Progress: 24/30 (24)\n",
      "Progress: 25/30 (25)\n",
      "Progress: 26/30 (26)\n",
      "Progress: 27/30 (27)\n",
      "Progress: 28/30 (28)\n",
      "Progress: 29/30 (29)\n",
      "Progress: 30/30 (30)\n",
      "Loading done! Count = 726 | Shape = (23, 128, 128)\n",
      "(726, 23, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "fire_folders = []\n",
    "look_back = 5   # 5 days sequence\n",
    "all_frames = []\n",
    "data_limit, loop_counter, loop_start = 30, 0, 0\n",
    "channel_descriptions = None\n",
    "base_path = \"./data\"\n",
    "\n",
    "target_shape_h, target_shape_w = 128, 128\n",
    "\n",
    "print('Loading...')\n",
    "\n",
    "for fire_folder in os.listdir(base_path):\n",
    "    loop_counter += 1\n",
    "    if loop_counter - loop_start > data_limit:\n",
    "        break\n",
    "    if loop_counter < loop_start:\n",
    "        continue\n",
    "    print('Progress: {0}/{1} ({2})'.format(loop_counter - loop_start, data_limit, loop_counter))\n",
    "    fire_folders.append(fire_folder)\n",
    "    for image_name in os.listdir(base_path + f\"/{fire_folder}\"):\n",
    "        file_path = base_path + f\"/{fire_folder}/{image_name}\"\n",
    "        \n",
    "        with rasterio.open(file_path, 'r') as geotiff:\n",
    "            src = geotiff.read()\n",
    "            channel_descriptions = geotiff.descriptions\n",
    "            zoom_factor = (1, target_shape_h / src.shape[1], target_shape_w / src.shape[2])\n",
    "            resized_src = zoom(src, zoom_factor, order=1)\n",
    "            resized_src = np.nan_to_num(resized_src, copy=True)\n",
    "            all_frames.append(resized_src)\n",
    "\n",
    "print(f'Loading done! Count = {len(all_frames)} | Shape = {all_frames[0].shape}')\n",
    "\n",
    "data_frames = np.stack(all_frames)\n",
    "print(data_frames.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6841d72-8dd3-4422-ac03-fe883227ade9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float32(-9018.023), np.float32(15955.0))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(data_frames), np.max(data_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b63e6605-90ff-4974-8e3a-9fc162fe0eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, minmax_scale\n",
    "\n",
    "#data_frames = (data_frames - min_bound) / (max_bound - min_bound)\n",
    "\n",
    "for c in range(23):\n",
    "    data_frames[:, c, :, :] = (data_frames[:, c, :, :] - min_values[c]) / (maX_testues[c] - min_values[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f108a33-775a-4c96-b7c4-d3f58572ec63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float32(0.0), np.float32(1.0))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(data_frames), np.max(data_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e484700-300e-4c16-9727-760c7fcc2f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(721, 5, 23, 128, 128)\n",
      "(721, 1, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "Y = []\n",
    "\n",
    "for t in range(0, data_frames.shape[0] - look_back):\n",
    "    x_seq = data_frames[t:t+look_back]               # shape: (5, 23, H, W)\n",
    "    y_mask = data_frames[t + look_back, 22]           # fire mask from channel 22\n",
    "\n",
    "    X.append(x_seq)\n",
    "    Y.append(y_mask)     # binarize\n",
    "\n",
    "X = np.stack(X)  # shape: (273, 5, 23, 128, 128)\n",
    "Y = np.expand_dims(np.stack(Y), axis=1)  # shape: (273, 1, 128, 128)\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba83c810-7239-4fd0-9197-fc435908392b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((576, 5, 23, 128, 128),\n",
       " (576, 1, 128, 128),\n",
       " (145, 5, 23, 128, 128),\n",
       " (145, 1, 128, 128))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_index = int(X.shape[0] * 0.8)\n",
    "\n",
    "X_train = X[:split_index]\n",
    "X_test = X[split_index:]\n",
    "\n",
    "Y_train = Y[:split_index]\n",
    "Y_test = Y[split_index:]\n",
    "\n",
    "X_train.shape, Y_train.shape, X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0d45016-b40e-4c53-bab7-b8329abc44c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([576, 5, 23, 128, 128]),\n",
       " torch.Size([576, 1, 128, 128]),\n",
       " torch.Size([145, 5, 23, 128, 128]),\n",
       " torch.Size([145, 1, 128, 128]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = torch.tensor(X_train).float()\n",
    "Y_train = torch.tensor(Y_train).float()\n",
    "\n",
    "X_test = torch.tensor(X_test).float()\n",
    "Y_test = torch.tensor(Y_test).float()\n",
    "\n",
    "X_train.shape, Y_train.shape, X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "296a456a-437b-4739-b922-69603fb006d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(576, 145)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class WildfireDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.Y[i]\n",
    "\n",
    "train_dataset = WildfireDataset(X_train, Y_train)\n",
    "test_dataset = WildfireDataset(X_test, Y_test)\n",
    "\n",
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0f23fba-c004-4498-a2ed-d1f68a67ab0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ebce47a-a105-4b95-bda8-821a1948d21c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a936eddf-fff5-4454-a910-e347569496d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (clstm): ConvLSTM(\n",
       "    (cell_list): ModuleList(\n",
       "      (0): ConvLSTMCell(\n",
       "        (conv): Conv2d(87, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (head): Sequential(\n",
       "    (0): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import convlstm\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        orig_size = (330, 257)\n",
    "\n",
    "        self.clstm = convlstm.ConvLSTM(\n",
    "            input_size=(128, 128),\n",
    "            input_dim=23,\n",
    "            hidden_dim=[64],\n",
    "            kernel_size=(3, 3),\n",
    "            num_layers=1\n",
    "        )\n",
    "        # (8, 64, 128, 128)\n",
    "        \n",
    "        self.head = nn.Sequential(\n",
    "            nn.Conv2d(64, 1, kernel_size=3, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        # (8, 1, 128, 128)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        outputs, last_states = self.clstm(x)\n",
    "\n",
    "        x = outputs[0][:, -1, :, :, :]\n",
    "        x = self.head(x)\n",
    "        return x\n",
    "\n",
    "model = Net().to(device)\n",
    "\n",
    "model.load_state_dict(torch.load('model-weights.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61c7dae3-aa93-4619-8a7c-d8ebc2da7655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99%; Precision: 0.16340744335717702\n"
     ]
    }
   ],
   "source": [
    "tolerance = 0.01\n",
    "accuracy = 0\n",
    "precision = 0\n",
    "accuracy_counter = 0\n",
    "precision_counter = 0\n",
    "show_figures = False\n",
    "\n",
    "for batch_index, batch in enumerate(test_loader):\n",
    "    x_batch, y_batch = batch[0].to(device), batch[1].to(device)\n",
    "    y_pred = model(x_batch)\n",
    "\n",
    "    y_batch_np = y_batch.cpu().detach().numpy()\n",
    "    y_pred_np = y_pred.cpu().detach().numpy()\n",
    "\n",
    "    for i in range(y_batch_np.shape[0]): # Each image in a batch = batch_size\n",
    "        split_val = 0.15\n",
    "        value_true = y_batch_np[i, 0]\n",
    "        value_true = np.piecewise(value_true, [value_true < split_val, value_true >= split_val], [0, 1])\n",
    "        if show_figures:\n",
    "            plt.figure()\n",
    "            plt.title(\"Actual\")\n",
    "            plt.imshow(value_true)\n",
    "\n",
    "        split_val = 0.5\n",
    "        value_pred = y_pred_np[i, 0]\n",
    "        value_pred = np.piecewise(value_pred, [value_pred < split_val, value_pred >= split_val], [0, 1])\n",
    "        if show_figures:\n",
    "            plt.figure()\n",
    "            plt.title(\"Predicted\")\n",
    "            plt.imshow(value_pred)\n",
    "\n",
    "        correct = np.abs(value_pred - value_true) <= tolerance\n",
    "        \n",
    "        accuracy += correct.sum() / correct.size\n",
    "        accuracy_counter += 1\n",
    "\n",
    "        TP = np.logical_and(value_pred == 1, value_true == 1).sum()\n",
    "        FP = np.logical_and(value_pred == 1, value_true == 0).sum()\n",
    "        \n",
    "        precision += TP / (TP + FP + 1e-7)  # Add small epsilon to avoid division by zero\n",
    "        precision_counter += 1\n",
    "        \n",
    "avg_accuracy = accuracy / accuracy_counter\n",
    "avg_precision = precision / precision_counter\n",
    "\n",
    "print(f\"Accuracy: {np.floor(avg_accuracy * 100):.0f}%; Precision: {avg_precision}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cf4272-f340-4a0b-a1ab-6f8bad772895",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
